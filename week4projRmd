---
title: "Practical Machine Learning Assignment Writeup"
author: "Rxy14"
output: html_document
---

```{r setup, include=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

## Introduction

The goal of the project is to predict the exercise manner (or quality) of six participants based on a number of predictor variables. The outcome is stored in the `classe` variable of the training set. I will explore several classifiers to solve this problem, notably **random forest**, **gradient boosting**, **linear discriminant analysis**, **support vector machine**, and **k-nearest neighbour**. Finally I will apply the best model to predict the 20 cases in the test set. I will further calculate the importance of the predictors (variables) based on our most successful model, and use the result of the importance to explore the underlying data. 


## Data import

Import required libraries, download data files, and use `read_csv()` to parse the csv files: 

```{r libs}
# Load required packages
library(caret)
library(readr)
library(corrplot)
```


```{r import, echo=TRUE, results='hide', warning=FALSE, message=FALSE}
# Download data files
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "pml-train.csv")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "pml-test.csv")

# Read data
train.orig <- read_csv("pml-train.csv")
train.orig$classe <- as.factor(train.orig$classe)
test.orig <- read_csv("pml-test.csv")
```


The training data consists of **`r dim(train.orig)[1]`** rows with **`r dim(train.orig)[2]`** columns. There are **`r dim(test.orig)[1]`** rows in the test set. The `classe` variable contains the following grades:

```{r overview}
# Table of outcome 'classe'
table(train.orig$classe)
```


## Data cleanup

The training dataset contains 7 columns that does not provide informative data for predicting the training outcome: **`r paste(colnames(train.orig)[1:7], sep=", ")`**. 


```{r cleandata1}
# Remove first 7 columns 
train <- train.orig
train <- train[, -c(1:7)]
```
 
In addition, there are **`r sum(apply(train.orig, 2, function(x) !all(!is.na(x))))`** variables with a large number of missing (`NA`) values that we will ommit for further analysis:


```{r cleandata2}
# Explore missing data rows/cols
missing <- apply(train, 2, function(x) sum(is.na(x)))
table(missing)

# Chop off columns with lots of missing data
excl.inds <- missing < 5
train <- train[, excl.inds]
```


There seems to be one row with `r max(apply(train, 1, function(x) sum(is.na(x))))` missing values. Delete row:

```{r cleandata3}
# Where are the other misisng data points?
excl.rows <- which(apply(train, 1, function(x) sum(is.na(x))) > 0)
train <- train[-excl.rows, ]
```

That leaves us with **`r ncol(train)-1`** predictor variables in the training dataset. 

## Data partitioning

For building the model we need a test set with known `classe` outcome variable. Let's split the training set into a test and training set using the `createDataPartition()` function of the caret package:

```{r splitdata}
# Split data set 
inTrain <- createDataPartition(y=train$classe, p=0.7, list=FALSE)
mytest <- train[-inTrain,]
train <- train[inTrain,]
```

This gives **`r nrow(mytest)`** rows in the test set and **`r nrow(train)`** rows in the final training set. 

## Model building

Set up a common `trainControl` object to use in all models we explore. We will use a **5-fold cross-validation** in the following models. 

```{r traincontrol}
# set up a trainControl object with 5-fold cross-validation
trc <- trainControl(method="cv", number=5)
```


### Random forest

We start with exploring the **random forest** algorithm (provided with the **ranger** package). Use the train control object defined above with 5-fold cross-validation. Specify `importance = 'impurity'` to obtain the importance of the variables in the fitting. Use `predict` on the test set, and call `confusionMatrix()` to evaluate the model.

```{r model_ranger}
# Random forest
mod_rf <- train(classe ~ ., 
                method="ranger", data=train, 
                trControl=trc, 
                importance = 'impurity')

# Predict on test data
pred_rf <- predict(mod_rf, mytest)

# Cross-table
table(pred_rf, mytest$classe)

# Calcualte confusion matrix
cm_rf <- confusionMatrix(pred_rf, mytest$classe)
```

This model provides a fantastic accuracy of **`r round(cm_rf$overall["Accuracy"], 3)`**. 

Use `varImp()` of the **caret** package to explore what's driving the prediction:

```{r varimp}
# Find varialbe importance
rfImp <- varImp(mod_rf)

# Make a barplot
df <- data.frame(Importance = unname(rfImp$importance), Vars=rownames(rfImp$importance))
df = df[order(df$Importance, decreasing = TRUE), ][1:15, ]

# Plot importance
ggplot(df, aes(x = reorder(Vars, Importance), 
    y = Importance, fill = Importance)) +
  geom_bar(stat='identity') + 
  labs(x = 'Variables') +
  coord_flip() 
```


Looks like a few key variables are driving most of the model with **pitch_forearm** and **roll_belt** being the most important. How does the underlying data look like? The following box plots illustrate some of they key variables. E.g. `pitch_forearm` close to 0 seems important for obtaining an **A**. 

```{r}
# Plot important variables
ggplot(train, aes(classe, pitch_forearm)) +
  geom_boxplot(aes(col=classe)) 

ggplot(train, aes(classe, roll_belt)) +
  geom_boxplot(aes(col=classe)) 

ggplot(train, aes(classe, magnet_dumbbell_z)) +
  geom_boxplot(aes(col=classe)) 
```




## Final prediction on the test set

Based on the random forest model we predict the 20 data points of the test set:

```{r predict}
predict(mod_rf, test.orig)
```


## Exploring other models 

Although the random forest model provides an accuracy of **`r round(cm_rf$overall["Accuracy"], 3)`**, we will check how other popular algorithms performs under default settings:

### Gradient Boosting


```{r model_gbm}
# Boosting
mod_gbm <- train(classe ~ .,
                 method="gbm", data=train, 
                 trControl=trc, verbose=FALSE)

pred_gbm <- predict(mod_gbm, mytest)
table(pred_gbm, mytest$classe)
cm_gbm <- confusionMatrix(pred_gbm, mytest$classe)
cm_gbm$overall["Accuracy"]
```


### Linear Discriminant Analysis

```{r model_lda}
# Linear Discriminant Analysis
mod_lda <- train(classe ~ .,
                 method="lda", data=train, 
                 trControl=trc)

pred_lda <- predict(mod_lda, mytest)
table(pred_lda, mytest$classe)
cm_lda <- confusionMatrix(pred_lda, mytest$classe)
cm_lda$overall["Accuracy"]
```


### k-nearest neighbors

```{r knn}
mod_knn <- train(classe ~ ., 
                method = "knn",
                data = train, 
                trControl = trc)
pred_knn <- predict(mod_knn, mytest)
table(pred_knn, mytest$classe)
cm_knn <- confusionMatrix(pred_knn, mytest$classe)
cm_knn$overall["Accuracy"]
```

### SVM

```{r svm}
mod_svm <- train(classe ~ ., 
                method = "svmLinear",
                data = train, 
                trControl = trc)
pred_svm <- predict(mod_svm, mytest)
table(pred_svm, mytest$classe)
cm_svm <- confusionMatrix(pred_svm, mytest$classe)
cm_svm$overall["Accuracy"]
```

## Preprocessing data

```{r model_gbm_pp}
# Boosting
mod_gbm_pp <- train(classe ~ .,
                 method="gbm", data=train, 
                 preProcess=c("center", "scale"),
                 trControl=trc, verbose=FALSE)

pred_gbm_pp <- predict(mod_gbm_pp, mytest)
table(pred_gbm_pp, mytest$classe)
cm_gbm_pp <- confusionMatrix(pred_gbm_pp, mytest$classe)
cm_gbm_pp$overall["Accuracy"]
```




## Conclusion

Random forest seems to be an excellent model for predicting exercise manner with an accuracy of **`r round(cm_rf$overall["Accuracy"], 3)`**. k-NN gives an accuracy of **`r round(cm_knn$overall["Accuracy"], 3)`** while gradient boosting gives an accuracy of **`r round(cm_gbm$overall["Accuracy"], 3)`**. 


## Current session info

```{r}
# Information about the current session
sessionInfo()
```
